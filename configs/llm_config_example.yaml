# LLM Configuration for Que Agents
# Supports multiple LLM platforms for flexibility and customization

llm:
  # Default LLM provider (openai, groq, anthropic, azure_openai, local)
  default_provider: "groq"
  # Temperature settings for different agent types
  temperature:
    customer_support: 0.3 # Lower temperature for consistent, factual responses
    marketing: 0.7 # Higher temperature for creative content generation
  # Model configurations for different providers
  providers:
    openai:
      api_key: "${OPENAI_API_KEY}"
      api_base: "${OPENAI_API_BASE}"
      models:
        default: "gpt-4-1106-preview"
        fast: "gpt-3.5-turbo"
        reasoning: "gpt-4"
      max_tokens: 4096
      timeout: 30
    groq:
      api_key: "${GROQ_API_KEY}"
      api_base: "https://api.groq.com/openai/v1"
      models:
        default: "llama3-70b-8192"
        fast: "llama3-8b-8192"
        reasoning: "mixtral-8x7b-32768"
      max_tokens: 8192
      timeout: 30
    anthropic:
      api_key: "${ANTHROPIC_API_KEY}"
      api_base: "https://api.anthropic.com"
      models:
        default: "claude-3-sonnet-20240229"
        fast: "claude-3-haiku-20240307"
        reasoning: "claude-3-opus-20240229"
      max_tokens: 4096
      timeout: 30
    azure_openai:
      api_key: "${AZURE_OPENAI_API_KEY}"
      api_base: "${AZURE_OPENAI_ENDPOINT}"
      api_version: "2024-02-15-preview"
      deployment_name: "${AZURE_OPENAI_DEPLOYMENT_NAME}"
      models:
        default: "gpt-4"
        fast: "gpt-35-turbo"
        reasoning: "gpt-4"
      max_tokens: 4096
      timeout: 30
    local:
      api_base: "http://localhost:11434/v1" # Ollama default endpoint
      models:
        default: "llama3:8b"
        fast: "llama3:8b"
        reasoning: "llama3:70b"
      max_tokens: 4096
      timeout: 60
  # Fallback configuration
  fallback:
    enabled: true
    providers: ["openai", "groq", "anthropic"] # Fallback order
  # Rate limiting
  rate_limit:
    requests_per_minute: 60
    tokens_per_minute: 150000
  # Retry configuration
  retry:
    max_attempts: 3
    backoff_factor: 2
    max_wait_time: 60
